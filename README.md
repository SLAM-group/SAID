# SAID

# <div align="center">A Benchmark For Social Media AI Detection. </div>

<p align="center" width="100%">
<a ><img src="assets/said_logo.png" alt="SAID-logo" style="width: 50%; margin: auto;"></a>
</p>

This is the repository for [Who Said That? Benchmarking Social Media
AI Detection](https://openreview.net/attachment?id=THtX863Io2&name=pdf)

## <a id="overview"></a>Overview

We create novel benchmark **SAID**(**S**ocial media **AI** **D**etection), which is used for social media AI detection. Unlike existing benchmarks, it incorporates real AI-generate text from popular social media platforms like Zhihu and Quora, and deals with content that reflects the sophisticated strategies employed by real AI users on the Internet which may evade detection or gain visibility, providing a more realistic and challenging evaluation landscape. The train and test dataset are composed from detector features.

The responses pair for human identification experiment in Table 3 is given in [pairs_zhihu](https://github.com/SLAM-group/SAID/blob/main/pairs_zhihu.xlsx)

For SAID_zhihu dataset, you can download from [here](https://drive.google.com/drive/folders/1M2SwWS68kRnN36dkbTgxLvFWUjZqnRz7).

For SAID_quora dataset, you can download from [here](https://drive.google.com/drive/folders/1A6er-AoQ0iZJGCq1KSvutB0pFWMUR9Zm).


We test three different detectors, and show the results below:

<p align="center" width="100%">
<a ><img src="assets/table 5.png" alt="Ada-Instruct" style="width: 100%; margin: auto;"></a>
</p>

## Citation

If you find this codebase useful in your research, please cite the following paper.
```
@article{
    // To be done
}
